## 第三章 线程池

#### 线程创建时机

线程维护核心线程数量，当达到核心数量时，再添加进来的任务会进入队列中等待，队列满了之后，再有任务会从队列头开始创建新的线程，当创建的线程超过最大线程数时，进行拒绝



#### 队列类型

1. 直接交接：SynchronousQueue，实际队列没有容量，只是做一下中转
2. 无界队列：LinkedBlockingQueue，不会创建新的线程，可以防止流量突增，但是如果监控不得当，会造成 oom
3. 有界队列：ArrayBlockingQueue，常用，队列容量满了就创建新的线程



#### Executor 常见线程池

* FixedThreadPool：固定线程数量，可能差生 oom
* SingleThreadExecutor：同上，只产生1个线程
* CacheThreadPool：无限线程，直接执行
* ScheduledThreadPool：定时，周期性
  * **.schedule(command, delay, unit);
  * **.scheduleAtFixedRate(command,  initialDelay, period, unit)



#### 线程数量设定

* CPU 密集型（加密、计算hash）：最佳为 CPU 核心数的 1-2 倍
* 耗时 IO 型（读写数据库、文件、网络读写）：一般大于核心很多倍，根据监控的繁忙为依据，保证线程空闲可衔接
* 线程数 = CPU 核心数 * （1 + 平均等待时间 / 平均工作时间）

--> 根据压测来判断是否添加或减少线程数



#### 拒绝策略

###### 拒绝时机

1. 当 Executor 已经关闭，新任务会被拒绝
2. Executor 对<u>最大线程和工作队列容量</u>使用**有限边界**并且**已经饱和**

###### 4种拒绝策略

* AbortPolicy：直接抛出异常
* DiscardPolicy：放弃策略
* DiscardOldestPolicy：丢弃最老的策略
* CallerRunsPolicy：任务提交者执行任务

#### 线程池中的线程

线程池中的线程会循环检查是否有新的任务，当有新的任务进入时会执行，完成后继续循环。

```java
try {
    while (task != null || (task = getTask()) != null) {
        // do something
    }
    completedAbruptly = false;
} finally {
    processWorkerExit(w, completedAbruptly);
}
```

#### 线程池状态

* running：接受新任务并处理排队任务
* shutdown：不接受新任务，但处理排队任务
* stop：不接受新的任务，中断正在进行的任务
* tidying：所有任务终止后进入
* terminated： terminate() 运行完成

#### execute() 方法执行过程

1. 获取工作线程数并判断是否小于核心线程
2. 如果 addWorker() 执行成功，返回
3. 再次判断是否运行，并添加到工作队列
4. 如果不是正在运行则执行 reject()
5. 如果线程因异常而没有了，则添加线程执行
6. 如果核心到了，队列也满了，开始增加线程执行任务
7. 直到线程数满了，再进入的任务将 reject()



## 第四章 ThreadLocal

#### ThreadLocal 使用场景

1. 每个线程需要一个独享对象（通常是**工具类**，典型如 SimpleDateFormat 和 Random）
2. 每个线程内需要**保存全局变量**（例如拦截器中获取用户信息，<u>每个请求都直接将第一个参数直接写入全局变量</u>），可以让不同方法直接使用，避免**参数传递麻烦**

##### 第一种  独享对象（SimpleDateFormat）

1. 只有几个线程，直接使用
2. 很多线程，需要使用**线程池**，否则耗内存
3. 线程*共用一个 SimpleDateFormat 对象*
4. *线程不安全*
5. **加锁**，*效率低*
6. 最终使用 **ThreadLocal**，通过 initialValue 设置



##### 第二种  保存全局变量（拦截器）

在第一个位置 set 相应变量之后，后面的 service 可以直接读取

> 此情景的另外一种解决方法：
>
> 可以用 static 的 ConcurrentHashMap，吧当前的线程 ID 作为 key，把 user 作为 value 来保存，可以做到线程隔离，但是仍然影响性能



#### ThreadLocal 优点总结

- 线程安全
- 执行效率高
- 内存占用低
    每个线程只需一个，即使执行不同的 Task，使用的也是同一份共享对象副本，这是线程独有的
- 不用传参，代码耦合降低

#### ThreadLocal 原理

> <u>**每个线程 Thread 持有一个 ThreadLocalMap 变量，里面用来保存对应的 ThreadLocal 对象**</u>

##### 重要方法

- **initialValue**()

延迟加载的方法，当调用 get 方法时，会调用这个方法，如果 set 过，则会返回 set 的值

如果 remove，则里面的对象会清空

一般使用匿名内部类的方法**重写 initialValue()**

- **set**()

设置对象

- **get**()

获取对应的 value，首次使用会调用 initialValue

- **remove**

清空对象

#### 防止内存泄漏

> 内存泄漏：某个对象不再有用，但是占有的内存无法回收

key 使用了弱引用进行创建

> 弱引用：如果对象只被弱引用关联，那么这个对象可以被回收
>
> 弱引用不会阻止 GC

ThreadLocal 存在以下调用链

> Thread ——> ThreadLocalMap ——> Entry（key 为null） ——> Value

value 是强引用，无法被回收

ThreadLocal 使用基本类型的封装类型，如果返回值使用的基本类型，并且没有设置初始值，可能导致**装箱拆箱**中**类型转换的空指针问题**。

#### Spring 使用 ThreadLocal

- DateTimeContextHolder
- RequestContextHolder
- ContextHolder



## 第五章 锁

#### 锁分类

- 乐观锁|悲观锁
- 可重入锁|不可重入锁（**ReentrantLock**）
- 公平锁|非公平锁
- 共享锁|排它锁（**ReentrantReadWriteLock**）
- 自旋锁|阻塞锁
- 可中断锁

#### Lock 接口

##### synchronized 存在的缺点

- **效率低**：锁释放少，试图获取锁时不能设定超时，无法终端试图获得锁的线程
- **不够灵活**：加锁、释放的时机单一，每个锁仅有单一条件
- 无法知道是否**成功获取到锁**

##### Lock 常用方法

###### lock()

普通的获取锁，无法获取则**等待**，**异常时不会释放锁**，最佳实践是**在 finally 中释放锁**。lock() 方法无法被中断，一旦**死锁**，就会永久等待

###### tryLock()

尝试获取锁，并**立即返回**，

###### tryLock(long time, TimeUnit unit)

**超时就放弃**

###### lockInterruptibly()

超时时间为无限，在等锁过程中**可被中断**

#### 锁的可见性

> happens-before 原则：一把锁在解锁前的所有操作，对于下一个锁是完全可见的

#### 锁分类2

- 是否锁住同步资源
  - 锁住：悲观锁
  - 不锁：乐观锁
- 多线程**是否共享**一把锁
  - 共享：共享锁
  - 不共享：独占锁
- 多线程竞争时，是否排队
  - 排队：公平锁
  - 尝试插队，插队失败再排队：非公平锁
- 同一个线程是否能重复获取一把锁
  - 可以：可重入锁
  - 不可以：不可重入锁
- 可否中断
  - 可以：可中断锁
  - 不可以：非可中断锁
- 等锁过程
  - 自旋：自旋锁
  - 阻塞：非自旋锁

#### 公平/非公平锁

- 公平：完全按照线程请求顺序来分配锁

- 非公平：不完全按顺序，一定情况可插队

> 非公平不提倡插队，而是在合适时机插队

##### 合适的时机

在队列首位的线程处于阻塞等待状态，而唤醒需要一定开销，此时可以安排正在运行的线程先进行执行，可以提高效率，**避免唤醒带来的空档期**

**tryLock() 方法可以直接插队，不管公平锁**

#### 共享锁

读写分离，读互不影响，可以共存，写只能同时一个写

两种插队策略：

- 读可以一直插队，可能造成写操作饥饿
- 读无法插写的队，损失一点效率，但是避免了饥饿
  - 读可以在队列第一个不是写操作的时候插队，直到队列第一个是写操作之后，就不能再插队了

#### 读写锁的锁升降级

**支持降级**，当写锁使用完后需要读操作，但是不想让人插队，就可以降级，开始读操作，也不影响其他线程进行读操作

**不支持升级**，读写锁由于不能同时写，但能同时读，所以当多个线程在读的时候，如果都想升级，但是需要其他线程放弃读锁，就会造成相互等待释放读锁，却无法升级成写锁的情况

#### 自旋锁和阻塞锁

- 阻塞锁
  - 线程如果得不到执行，就进入阻塞状态，等能执行时，进行唤醒
  - 进行唤醒将消耗较多的 cpu 资源，但是可能执行的操作并不多，就浪费了 cpu 资源
- 自旋锁
  - 在锁很快被释放的情况下，使用自旋去等待释放，当锁释放后可以立即得到执行，不必消耗切换线程的资源
  - 如果锁占用时间很长，将造成**资源消耗线性增长**